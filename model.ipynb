{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13장 모델의 성능 검증하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/taehojo/taehojo.github.io/master/assets/images/linktocolab.png\" align=\"left\"/> ](https://colab.research.google.com/github/taehojo/deeplearning/blob/master/colab/ch13-colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  데이터의 확인과 예측 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시간</th>\n",
       "      <th>시가</th>\n",
       "      <th>고가</th>\n",
       "      <th>저가</th>\n",
       "      <th>종가</th>\n",
       "      <th>전일대비</th>\n",
       "      <th>거래량</th>\n",
       "      <th>거래대금</th>\n",
       "      <th>누적체결매도수량</th>\n",
       "      <th>상장주식수</th>\n",
       "      <th>...</th>\n",
       "      <th>외국인현보유비율</th>\n",
       "      <th>수정주가일자</th>\n",
       "      <th>수정주가비율</th>\n",
       "      <th>기관순매수량</th>\n",
       "      <th>기관누적순매수량</th>\n",
       "      <th>등락주선</th>\n",
       "      <th>등락비율</th>\n",
       "      <th>예탁금</th>\n",
       "      <th>주식회전율</th>\n",
       "      <th>거래성립률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20221103</th>\n",
       "      <td>1530</td>\n",
       "      <td>59200</td>\n",
       "      <td>59200</td>\n",
       "      <td>59200</td>\n",
       "      <td>59200</td>\n",
       "      <td>0</td>\n",
       "      <td>1859760</td>\n",
       "      <td>110097790000</td>\n",
       "      <td>5944330</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20221103</th>\n",
       "      <td>1520</td>\n",
       "      <td>59500</td>\n",
       "      <td>59700</td>\n",
       "      <td>59500</td>\n",
       "      <td>59700</td>\n",
       "      <td>0</td>\n",
       "      <td>193177</td>\n",
       "      <td>11510350000</td>\n",
       "      <td>5944330</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20221103</th>\n",
       "      <td>1519</td>\n",
       "      <td>59500</td>\n",
       "      <td>59600</td>\n",
       "      <td>59500</td>\n",
       "      <td>59600</td>\n",
       "      <td>0</td>\n",
       "      <td>49046</td>\n",
       "      <td>2921250000</td>\n",
       "      <td>5893859</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20221103</th>\n",
       "      <td>1518</td>\n",
       "      <td>59600</td>\n",
       "      <td>59600</td>\n",
       "      <td>59500</td>\n",
       "      <td>59600</td>\n",
       "      <td>0</td>\n",
       "      <td>20663</td>\n",
       "      <td>1230500000</td>\n",
       "      <td>5874904</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20221103</th>\n",
       "      <td>1517</td>\n",
       "      <td>59500</td>\n",
       "      <td>59600</td>\n",
       "      <td>59500</td>\n",
       "      <td>59600</td>\n",
       "      <td>0</td>\n",
       "      <td>20021</td>\n",
       "      <td>1192690000</td>\n",
       "      <td>5864749</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            시간     시가     고가     저가     종가  전일대비      거래량          거래대금  \\\n",
       "20221103  1530  59200  59200  59200  59200     0  1859760  110097790000   \n",
       "20221103  1520  59500  59700  59500  59700     0   193177   11510350000   \n",
       "20221103  1519  59500  59600  59500  59600     0    49046    2921250000   \n",
       "20221103  1518  59600  59600  59500  59600     0    20663    1230500000   \n",
       "20221103  1517  59500  59600  59500  59600     0    20021    1192690000   \n",
       "\n",
       "          누적체결매도수량  상장주식수  ...  외국인현보유비율  수정주가일자  수정주가비율  기관순매수량  기관누적순매수량  \\\n",
       "20221103   5944330      0  ...       0.0       0     0.0       0         0   \n",
       "20221103   5944330      0  ...       0.0       0     0.0       0         0   \n",
       "20221103   5893859      0  ...       0.0       0     0.0       0         0   \n",
       "20221103   5874904      0  ...       0.0       0     0.0       0         0   \n",
       "20221103   5864749      0  ...       0.0       0     0.0       0         0   \n",
       "\n",
       "          등락주선  등락비율  예탁금  주식회전율  거래성립률  \n",
       "20221103     0   0.0    0    0.0    0.0  \n",
       "20221103     0   0.0    0    0.0    0.0  \n",
       "20221103     0   0.0    0    0.0    0.0  \n",
       "20221103     0   0.0    0    0.0    0.0  \n",
       "20221103     0   0.0    0    0.0    0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 입력\n",
    "df = pd.read_csv('../data/코스피/005930_삼성전자.csv', index_col=0)\n",
    "\n",
    "# 첫 5줄을 봅니다. \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189999, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 6833/19000 [=========>....................] - ETA: 46s - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5540\\3405687902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# 모델을 실행합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\TJ\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TJ\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TJ\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TJ\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TJ\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TJ\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TJ\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\TJ\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TJ\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 모델을 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(24,  input_dim=23, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X, y, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습셋과 테스트셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 라이브러리를 설치하는 부분입니다. 처음 설치한다면 아래 #를 삭제하고 실행하세요.\n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/sonar3.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:60]\n",
    "y = df.iloc[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 셋과 테스트 셋을 구분합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.4828\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.6276\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6345\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6828\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.7310\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7517\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.7655\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.7517\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7655\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7517\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7448\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7517\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7586\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7793\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.8000\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7931\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8276\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8276\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8276\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8345\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8138\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8138\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8207\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8345\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8345\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8414\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8345\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8483\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8414\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8552\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8690\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8207\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8828\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8690\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8138\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8621\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8690\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8759\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8828\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8690\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8690\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8690\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8552\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8690\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8828\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8690\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8759\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8966\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8966\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8759\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8966\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.9034\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9103\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.9103\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.9103\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.9034\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8966\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8828\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.9034\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.9172\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.9103\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9172\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9103\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.9034\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.9172\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.9103\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.9034\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9241\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.9241\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9103\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9103\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.9172\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.9310\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9379\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9310\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.9103\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9103\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9310\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9241\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9310\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9517\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9103\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9448\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9448\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9379\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9172\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9103\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9517\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9379\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9448\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9517\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9517\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.9172\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9379\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9517\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9310\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9448\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9586\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9517\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9172\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9448\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9448\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9448\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9379\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9586\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9379\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9586\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9724\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1697 - accuracy: 0.9655\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9655\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9586\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.9655\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9586\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9655\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9655\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9517\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9586\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.9724\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9655\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9724\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.9655\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9793\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9724\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9586\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9793\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9793\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9793\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9724\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9793\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9793\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9793\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9793\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9724\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9793\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9793\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9793\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9724\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9724\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9724\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9793\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.9724\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9793\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9793\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9793\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9793\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9793\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9793\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9793\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1213 - accuracy: 0.9724\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9724\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9793\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9793\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9793\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9793\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9793\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9793\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9793\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9793\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9793\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9793\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9793\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9793\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9793\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9793\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9793\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9793\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9793\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.9793\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9793\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9793\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9793\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9793\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9862\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9793\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9793\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9793\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9793\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9793\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9862\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.9793\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9793\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9793\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9793\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9793\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9931\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9931\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9862\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9862\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9931\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9862\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9931\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.9931\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9931\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9931\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9931\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9931\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9862\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9931\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9862\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "# 모델을 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(24,  input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8413\n",
      "Test accuracy: 0.841269850730896\n"
     ]
    }
   ],
   "source": [
    "# 모델을 테스트셋에 적용해 정확도를 구합니다. \n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 저장과 재사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 저장합니다. \n",
    "model.save('./data/model/my_model.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트를 위해 조금 전 사용한 모델을 메모리에서 삭제합니다.\n",
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8413\n",
      "Test accuracy: 0.841269850730896\n"
     ]
    }
   ],
   "source": [
    "# 모델을 새로 불러옵니다.\n",
    "model = load_model('./data/model/my_model.hdf5') \n",
    "\n",
    "# 불러온 모델을 테스트셋에 적용해 정확도를 구합니다. \n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. k겹 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 입력합니다.\n",
    "df = pd.read_csv('./data/sonar3.csv', header=None)\n",
    "\n",
    "# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:60]\n",
    "y = df.iloc[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.7381\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7071 - accuracy: 0.8095\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x000001EDE50D60D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8810\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001EDE5112AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.9024\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.7317\n",
      "정확도: [0.738095223903656, 0.8095238208770752, 0.8809523582458496, 0.9024389982223511, 0.7317073345184326]\n",
      "정확도 평균: 0.8125435471534729\n"
     ]
    }
   ],
   "source": [
    "#몇 겹으로 나눌 것인지를 정합니다. \n",
    "k=5\n",
    "\n",
    "#KFold 함수를 불러옵니다. 분할하기 전에 샘플이 치우치지 않도록 섞어 줍니다.\n",
    "kfold = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "#정확도가 채워질 빈 리스트를 준비합니다.\n",
    "acc_score = []\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential() #딥러닝 모델의 구조를 시작합니다.\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "#K겹 교차 검증을 이용해 k번의 학습을 실행합니다. \n",
    "for train_index , test_index in kfold.split(X):  # for문에 의해서 k번 반복합니다. spilt()에 의해 k개의 학습셋, 테스트셋으로 분리됩니다.\n",
    "    X_train , X_test = X.iloc[train_index,:], X.iloc[test_index,:]  \n",
    "    y_train , y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = model_fn()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history=model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=0) \n",
    "    \n",
    "    accuracy = model.evaluate(X_test, y_test)[1]  #정확도를 구합니다.\n",
    "    acc_score.append(accuracy)  #정확도 리스트에 저장합니다.\n",
    "\n",
    "#k번 실시된 정확도의 평균을 구합니다.\n",
    "avg_acc_score = sum(acc_score)/k\n",
    "\n",
    "#결과를 출력합니다.\n",
    "print('정확도:', acc_score)\n",
    "print('정확도 평균:', avg_acc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "05247f0879db25b58c9f4dbf50b6eaf626832b6fbf3893d9d370e5540f006961"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
