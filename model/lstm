import os
import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.metrics import accuracy_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OneHotEncoder

from tensorflow.keras import optimizers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.layers import Dropout, LeakyReLU, Input
from tensorflow.keras.layers import BatchNormalization, Activation

##############################################################################################

def file_open(file_open):
    file_ = os.listdir(f'{file_open}')
    file_.sort()
    
    return file_

#########################################################################################
# 레이블로 나올 수 있는 category 전부를 가지고 있는 데이터 프레임 생성
category_label = pd.DataFrame({'pct_label' : [0,1,2,3,4,5,6,7,8,9,10
                                    ,11,12,13,14,15,16,17,18,19,20
                                    ,21,22,23,24,25,26,27,28,29,30
                                    ,31,32,33,34,35,36,37,38,39,40
                                    ,41,42,43,44,45,46,47,48,49,50
                                    ,51,52,53,54,55,56,57,58,59,60]})

# 위에 데이터 프레임을 원핫 인코딩의 fit해줌 -> 이후 원핫 인코딩시 61개로 맞춰짐
ohe = OneHotEncoder(sparse=False)
ohe_test = ohe.fit_transform(category_label[['pct_label']])

#########################################################################################

# 학습할 데이터가 저장된 경로
lstm_train_dir = './temp_data/'
# 학습할 데이터 프레임이 들어 있는 리스트
lstm_train_data = file_open(lstm_train_dir)
# 학습할 데이터 프레임 한번에 저장할 빈 데이터 프레임
stock_df = pd.DataFrame()

# 학습할 데이터 프레임을 하나씩 꺼내서 전부 concat
for train_data in lstm_train_data:
    temp = pd.read_csv(f'./temp_data/{train_data}')
    
    stock_df = pd.concat([stock_df, temp], axis=0)

# 데이터 label을 1의 자리로 절사
stock_df['pct_label'] = stock_df['pct_label'].apply(np.floor)


# 학습할 데이터 프레임의 원한 인코딩
y_stock_df = ohe.transform(stock_df[['pct_label']])


# value data MinMaxScaler 
min_max_scaler = MinMaxScaler()
X_stock_df = stock_df.iloc[:,0:-1] # value data 추출
X_stock_sc = min_max_scaler.fit_transform(X_stock_df)

# 학습/ 테스트 셋 분리
X_train, X_test, y_train, y_test = train_test_split(X_stock_sc, y_stock_df, test_size=0.3, shuffle=True, random_state=42)

# 학습 데이터 차원 변경 -> lstm에 사용하기 위해
X_train = X_train.reshape(X_train.shape[0], 21, 1)
X_test = X_test.reshape(X_test.shape[0], 21, 1)

inputs = Input(shape=(X_train.shape[-2],X_train.shape[-1]))
lstm_out = LSTM(244, dropout=0.2, return_sequences=True)(inputs)
lstm_out = BatchNormalization()(lstm_out)
lstm_out = Activation('LeakyReLU')(lstm_out)
lstm_out = LSTM(122, dropout=0.2)(lstm_out)
lstm_out = BatchNormalization()(lstm_out)
lstm_out = Activation('LeakyReLU')(lstm_out)
lstm_out = Dense(61)(lstm_out)
lstm_out = BatchNormalization()(lstm_out)
lstm_out = Activation('softmax')(lstm_out)

# 증가가 없을 시 stop
early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)

# 최적화 모델이 저장될 경로
modelpath="./model/lstm_test.hdf5" ##### 변경해야함

# 최적화 모델을 업데이트하고 저장
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)

model = Model(inputs=inputs, outputs=lstm_out)
model.summary()
model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.001, decay=1e-7), metrics=['accuracy'])
history=model.fit(X_train, y_train, epochs=50, batch_size=128,verbose=1, validation_data=(X_test, y_test), callbacks=[early_stopping_callback, checkpointer])

# 최적화 모델의 가중치 적용
model.load_weights(modelpath)

# 예측할 새 데이터
pred_df = pd.read_csv('./temp_data/test_complete_A066970.csv') #### 변경

# 예측할 데이터 label 전처리
pred_df['pct_label'] = pred_df['pct_label'].apply(np.floor)
y_pred_df = ohe.transform(pred_df[['pct_label']])

# 예측할 데이터 value 전처리
X_pred_df = pred_df.iloc[:,0:-1]
X_pred_sc = min_max_scaler.fit_transform(X_pred_df)
X_pred = X_pred_sc.reshape(X_pred_sc.shape[0], 21, 1)

# 예측값 구하기
predict = model.predict(X_pred)

# 각 로우별로 최대값의 인덱스
pred = tf.argmax(predict,1).numpy()
test = tf.argmax(y_pred_df,1).numpy()

# 정확도 측정
acc = accuracy_score(test, pred)