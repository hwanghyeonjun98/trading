{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWAlCbf9KymD"
   },
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label():\n",
    "\n",
    "    # Concat 데이터 불러오기\n",
    "    files_list = os.listdir('../data/20221121/concat/')\n",
    "    \n",
    "    for file_name in tqdm(files_list):\n",
    "\n",
    "        stock_info = pd.read_csv(f'../data/20221121/concat/{file_name}', index_col=0)\n",
    "        \n",
    "        code = 'A' + file_name.split('_')[-2]\n",
    "\n",
    "        # 데이터 프레임에서 날짜 인덱스 추출\n",
    "        date = stock_info.index.unique()\n",
    "\n",
    "        # label 컬럼 추가 후 0으로 초기화\n",
    "        stock_info['label'] = 0\n",
    "\n",
    "        # 업데이트에 사용할 데이터 프레임 생성\n",
    "        update_stock_info = pd.DataFrame()\n",
    "\n",
    "        # labeling\n",
    "        for day in date:\n",
    "\n",
    "            # 특정일의 Data 추출\n",
    "            select_day = stock_info.loc[day].copy()\n",
    "            select_day['label'] = 0\n",
    "            \n",
    "            # 특정일의 Row 만큼 반복\n",
    "            for row in range(len(select_day)):\n",
    "                \n",
    "                # 특정일의 현재 row 이후 최대 고가를 추출\n",
    "                next_price = select_day[-row-1::-1]['고가'].max()\n",
    "\n",
    "                # 추출한 최대 고가를 label 컬럼에 대입\n",
    "                select_day.iloc[-row-1,-1] = next_price\n",
    "                next_price = 0\n",
    "            \n",
    "            # 특정일 label이 추가된 DF를 업데이트할 DF에 concat\n",
    "            update_stock_info = pd.concat([update_stock_info, select_day])\n",
    "\n",
    "        trans = update_stock_info.loc[:,['고가','label']]\n",
    "        trans = trans.rename(columns={'label':'pct_label'}).T\n",
    "\n",
    "        get_trans = trans.pct_change().T.iloc[:,-1]\n",
    "        \n",
    "        update_stock_info = pd.concat([update_stock_info, get_trans], axis=1)\n",
    "        update_stock_info = update_stock_info.drop(['label'], axis=1)\n",
    "\n",
    "        update_stock_info['pct_label'] = update_stock_info['pct_label'].mul(100)\n",
    "        update_stock_info['pct_label'] = update_stock_info['pct_label'].round(1)\n",
    "\n",
    "        update_stock_info.to_csv('../data/20221121/complete/{0}.csv'.format(code), encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 56/2406 [41:43<28:57:24, 44.36s/it]"
     ]
    }
   ],
   "source": [
    "label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ch12-colab.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/taehojo/deeplearning/blob/master/colab/ch12-colab.ipynb",
     "timestamp": 1642728385932
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d66cacf706517507cdd0b4e234574712ba1b713b08143b1cf3924a4cf14baeb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
