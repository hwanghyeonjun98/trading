{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from datetime import timedelta, date\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf gpu 메모리 관련 코드 \n",
    "gpus = tf.config.list_physical_devices(device_type = 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(date.today() - timedelta(days=1)).replace('-','')\n",
    "saveday = str(date.today() - timedelta(days=2)).replace('-','')\n",
    "# mysql connect하기 위한 아이디 비밀번호 포트 데이터베이스 등록 및 conn 리턴\n",
    "def sqlalchemy_connect_ip(ip_address, db_name):\n",
    "    engine = create_engine(\"mysql+pymysql://admin:\"\n",
    "                +\"big15\" # user password\n",
    "                +\"@{0}:3306/{1}?charset=utf8\".format(ip_address, db_name)\n",
    "                , encoding='utf8')\n",
    "    \n",
    "    return engine.connect()\n",
    "\n",
    "# mysql connect하기 위한 아이디 비밀번호 포트 데이터베이스 등록 및 conn 리턴\n",
    "def get_pymysql_connection(ip_address, db_name):\n",
    "\n",
    "    conn = pymysql.connect(host=ip_address, user='admin', password='big15'\n",
    "                        , db=db_name, charset='utf8')\n",
    "\n",
    "    return conn\n",
    "\n",
    "#DB 내 존재하는 테이블(종목) 리스트 추출\n",
    "def get_pymysql_stock_list(conn, db_name):\n",
    "\n",
    "    # 원하는 폴더의 테이블(종목) 추출\n",
    "    sql = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = '{0}'\".format(db_name)\n",
    "\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql)\n",
    "            result = [item[0] for item in cur.fetchall()]\n",
    "            cur.close()\n",
    "\n",
    "            return result\n",
    "               \n",
    "# 병합을 위해 날짜만을 가지고 있는 데이터 프레임 생성\n",
    "def get_empty_day_df(sqlalchemy_conn):\n",
    "     \n",
    "    sql = \"SELECT * FROM investing_data.aedkrw내역 where 날짜 > 20211130 and 날짜 < {0}\".format(today)\n",
    "            \n",
    "    table_data = sqlalchemy_conn.execute(sql) \n",
    "    empty_day_df = pd.DataFrame(table_data.fetchall())  # DB내 테이블을 DF로 변환\n",
    "    \n",
    "    empty_day_df = empty_day_df.drop(columns=['AEDKRW내역_종가','AEDKRW내역_오픈','AEDKRW내역_고가'\n",
    "                                      ,'AEDKRW내역_저가','AEDKRW내역_거래량','AEDKRW내역_변동']) # 날짜를 제외한 컬럼 drop\n",
    "    \n",
    "    empty_day_df.to_pickle('../pickle/pickle_df/empty/{0}_1년.pkl'.format(saveday))\n",
    "    \n",
    "    return empty_day_df\n",
    "\n",
    "\n",
    "# investing Data로 이루어진 데이터 프레임 추출\n",
    "def get_sqlalchemy_investing_df(conn, empty_day_df, investing_table_list):\n",
    "    \n",
    "    investing_df = pd.DataFrame(empty_day_df)\n",
    "    investing_df['날짜'] = investing_df['날짜'].astype(str).astype(int) # 날짜 타입 int로 통일\n",
    "    for table in investing_table_list:\n",
    "        \n",
    "        sql = \"SELECT * FROM investing_data.`{0}` where 날짜 > 20211130 and 날짜 < {1}\".format(table, today)\n",
    "        table_data= conn.execute(sql)\n",
    "        table_df = pd.DataFrame(table_data.fetchall())  # DB내 테이블을 DF로 변환\n",
    "        table_df['날짜'] = table_df['날짜'].astype(str).astype(int) # 날짜 타입 int로 통일\n",
    "        \n",
    "        investing_df = pd.merge(investing_df, table_df,on='날짜', how='left') # investing data들을 하나의 df로 제작\n",
    "        \n",
    "    # 빈 값 채워주기    \n",
    "    for c in list(investing_df.columns):\n",
    "        if c.split('_')[-1] == '거래량' or c.split('_')[-1] == '변동':\n",
    "            investing_df[c] = investing_df[c].fillna(0)\n",
    "        else:\n",
    "            investing_df[c] = investing_df[c].fillna(method='bfill')\n",
    "            investing_df[c] = investing_df[c].fillna(method='ffill')\n",
    "            \n",
    "    return investing_df  \n",
    "\n",
    "# stock df와 investing df를 병합\n",
    "def get_sqlalchemy_stock_investing_merge_df(conn, stock_table_list, investing_df):\n",
    "    \n",
    "    complete_df = pd.DataFrame()\n",
    "    investing_df['날짜'] = investing_df['날짜'].astype(str).astype(int) # 날짜 타입 int로 통일\n",
    "    for table in tqdm(stock_table_list):\n",
    "        sql = \"SELECT * FROM stock_info.`{0}` where 날짜 > 20211130 and 날짜 < {1}\".format(table, today)\n",
    "        table_data = conn.execute(sql)\n",
    "        stock_df = pd.DataFrame(table_data.fetchall()) # DB내 테이블을 DF로 변환\n",
    "        \n",
    "        drop_list = ['외국인주문한도수량','외국인주문가능수량','수정주가일자','수정주가비율']\n",
    "        stock_df.drop(drop_list,axis=1, inplace=True)\n",
    "        \n",
    "        stock_df['날짜'] = stock_df['날짜'].astype(str).astype(int) # 날짜 타입 int로 통일\n",
    "        merge_df = pd.merge(stock_df, investing_df, on='날짜') # stock df 와 investing df 를 날짜 기준으로 merge\n",
    "\n",
    "        complete_df = pd.concat([complete_df, merge_df], axis=0) # merge가 된 df들을 concat하여 하나의 df로 제작\n",
    "        \n",
    "    conn.close()\n",
    "    return complete_df      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymysql_conn = get_pymysql_connection('192.168.50.123', 'investing_data')\n",
    "sqlalchemy_conn = sqlalchemy_connect_ip('192.168.50.123', 'investing_data')\n",
    "investing_table_list = get_pymysql_stock_list(pymysql_conn, 'investing_data')\n",
    "empty_day_df = get_empty_day_df(sqlalchemy_conn)\n",
    "investing_df = get_sqlalchemy_investing_df(sqlalchemy_conn, empty_day_df, investing_table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:09<00:00,  6.98s/it]\n"
     ]
    }
   ],
   "source": [
    "stock_table_list = ['005930','373220','207940','000660','051910','247540','091990','066970','293490','028300'] # 대형주\n",
    "complete_df = get_sqlalchemy_stock_investing_merge_df(sqlalchemy_conn, stock_table_list, investing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_col_list = ['전일대비','상장주식수','시가총액','외국인현보유수량'\n",
    "                ,'외국인현보유비율','기관순매수량','기관누적순매수량'\n",
    "                , '년', '월', '일']   \n",
    "investing_col_list= list(investing_df.columns.drop('날짜'))\n",
    "\n",
    "shift_list = day_col_list + investing_col_list\n",
    "\n",
    "for col in shift_list:\n",
    "    complete_df[col] = complete_df[col].shift(381)\n",
    "complete_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "investing_df.to_pickle('../pickle/pickle_df/investing/{0}_1년_10개.pkl'.format(saveday))\n",
    "complete_df.to_pickle('../../data/pickle_complete/대형주_{0}_1년_10개.pkl'.format(saveday))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.../../data/pickle_complete/대형주_20221206_6개월_10개.pkl', 'rb') as f:\n",
    "    stock_df = pickle.load(f)\n",
    "# 상관 계수 높은 거 추출\n",
    "corr_matrix = stock_df.corr()\n",
    "cor = corr_matrix[\"pct_label\"]\n",
    "# cor.to_pickle('../pickle/pickle_corr/대형주_{0}_6개월_10개.pkl'.format(saveday))\n",
    "\n",
    "corr_matrix.to_pickle('../pickle/pickle_corr_matrix/대형주_20221206_6개월_10개.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/pickle_corr/대형주_20221206_1년_10개.pkl', 'rb') as f:\n",
    "    cor = pickle.load(f)\n",
    "    \n",
    "co= co.drop('날짜')\n",
    "cor1 = co[(co.values>0.04) | (co.values<-0.04) |\n",
    "           (co.index == '고가') | (co.index == '시가') | \n",
    "           (co.index == '종가') | (co.index == '저가')  ]\n",
    "cor1 = cor1.drop('pct_label')\n",
    "cor1.to_pickle('../pickle/pickle_corr/대형주_20221206_1년_10개_035.pkl')\n",
    "len(cor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1287it [00:11, 113.23it/s]\n",
      "100%|██████████| 989/989 [00:00<00:00, 298407.79it/s]\n",
      "100%|██████████| 6/6 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/pickle_complete/대형주_20221206_6개월_10개.pkl', 'rb') as f:\n",
    "    stock_df = pickle.load(f)\n",
    "with open('../pickle/pickle_corr_matrix/대형주_20221206_6개월_10개.pkl', 'rb') as f:\n",
    "    cor_df = pickle.load(f)\n",
    "    \n",
    "drop_list = []\n",
    "for i, cor in tqdm(enumerate(cor_df.columns)):\n",
    "    for v, j in zip(cor_df.loc[cor].values, cor_df.iloc[i].index ):\n",
    "        # print(v)\n",
    "        if (v > 0.8) & (v!=1) & (j not in drop_list):\n",
    "            drop_list.append(j)\n",
    "            \n",
    "cor_list = list(cor_df.columns)\n",
    "for i in tqdm(drop_list):\n",
    "    cor_list.remove(i)\n",
    "    \n",
    "essential_list = ['날짜','시간','시가','고가', '저가', '종가'] \n",
    "for e in tqdm(essential_list):\n",
    "    if e not in cor_list: \n",
    "        cor_list.append(e)\n",
    "\n",
    "\n",
    "corr_df = stock_df[cor_list].corr()\n",
    "new_corr = corr_df[\"pct_label\"]\n",
    "new_corr.to_pickle('../pickle/pickle_corr_complete/대형주_20221206_6개월_10개.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../pickle/pickle_corr_complete/대형주_20221206_6개월_10개.pkl', 'rb') as f:\n",
    "    new_corr = pickle.load(f)\n",
    "\n",
    "new_corr= new_corr.drop('날짜')\n",
    "complete_cor = new_corr[(new_corr.values>0.05) | (new_corr.values<-0.05) |\n",
    "                (new_corr.index == '고가') | (new_corr.index == '시가') | \n",
    "                (new_corr.index == '종가') | (new_corr.index == '저가')  ]\n",
    "complete_cor = complete_cor.drop('pct_label')\n",
    "complete_cor.to_pickle('../pickle/pickle_corr_complete/대형주_20221206_6개월_10개_05.pkl')\n",
    "len(complete_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('tfgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c0d917b331d00af62a730bf0430d82d3e7e85b82585d8406073ee97cc7ea825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
